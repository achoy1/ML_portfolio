{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset, for our purposes, simple digit dataset with 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial testing of SVM algorithm on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 0.9981447124304267, testing accuracy is: 0.9444444444444444\n",
      "Precision score: 0.952705314009662\n",
      "Recall score: 0.9414181286549708\n",
      "F1 score: 0.9410935310742756\n",
      "Hamming loss: 0.05555555555555555\n",
      "Training accuracy is: 0.9962894248608535, testing accuracy is: 0.9944444444444445\n",
      "Precision score: 0.9944444444444445\n",
      "Recall score: 0.99375\n",
      "F1 score: 0.9939170506912444\n",
      "Hamming loss: 0.005555555555555556\n",
      "Training accuracy is: 0.9969078540507111, testing accuracy is: 0.9777777777777777\n",
      "Precision score: 0.9813636363636362\n",
      "Recall score: 0.9777433780529755\n",
      "F1 score: 0.9786715328178743\n",
      "Hamming loss: 0.022222222222222223\n",
      "Training accuracy is: 0.9962894248608535, testing accuracy is: 0.9444444444444444\n",
      "Precision score: 0.9448099415204678\n",
      "Recall score: 0.9427760577915377\n",
      "F1 score: 0.9426126355538121\n",
      "Hamming loss: 0.05555555555555555\n",
      "Training accuracy is: 0.9962894248608535, testing accuracy is: 0.9777777777777777\n",
      "Precision score: 0.9802130325814536\n",
      "Recall score: 0.9780701754385965\n",
      "F1 score: 0.9782909962321726\n",
      "Hamming loss: 0.022222222222222223\n",
      "Training accuracy is: 0.9962894248608535, testing accuracy is: 0.9888888888888889\n",
      "Precision score: 0.9901913875598087\n",
      "Recall score: 0.9894444444444443\n",
      "F1 score: 0.989550470480703\n",
      "Hamming loss: 0.011111111111111112\n",
      "Training accuracy is: 0.9975262832405689, testing accuracy is: 0.9722222222222222\n",
      "Precision score: 0.9739880952380953\n",
      "Recall score: 0.972420634920635\n",
      "F1 score: 0.9725588533686697\n",
      "Hamming loss: 0.027777777777777776\n",
      "Training accuracy is: 0.9962917181705809, testing accuracy is: 0.9441340782122905\n",
      "Precision score: 0.9601648351648352\n",
      "Recall score: 0.9433608531131752\n",
      "F1 score: 0.9467053596840831\n",
      "Hamming loss: 0.055865921787709494\n",
      "Training accuracy is: 0.9975278121137207, testing accuracy is: 0.9720670391061452\n",
      "Precision score: 0.9728070175438598\n",
      "Recall score: 0.9717105263157896\n",
      "F1 score: 0.9712526812526813\n",
      "Hamming loss: 0.027932960893854747\n",
      "Training accuracy is: 0.9969097651421508, testing accuracy is: 0.9441340782122905\n",
      "Precision score: 0.9523427552839318\n",
      "Recall score: 0.9458479532163743\n",
      "F1 score: 0.943986849963081\n",
      "Hamming loss: 0.055865921787709494\n",
      "Average training accuracy: 0.9968465844591574, standard deviation: 0.0006456413410141737\n",
      "Average testing accuracy: 0.9660335195530726, standard deviation: 0.018898292389128706\n",
      "Average precision score: 0.9703030459710194, standard deviation: 0.016135926103640567\n",
      "Average recall score: 0.9656542151948498, standard deviation: 0.01933441331577753\n",
      "Average f1 score: 0.9658639961118596, standard deviation: 0.01933962225155187\n",
      "Average hamming loss score: 0.03396648044692738, standard deviation: 0.01889829238912868\n"
     ]
    }
   ],
   "source": [
    "# Implementing 10-fold cross validation to test model\n",
    "cv = KFold(n_splits=10, shuffle=False, random_state=234)\n",
    "\n",
    "# lists to store model metrics for analysis\n",
    "store_train_acc = []\n",
    "store_acc = []\n",
    "\n",
    "store_precs = []\n",
    "store_recs = []\n",
    "store_f1s = []\n",
    "store_hloss = []\n",
    "\n",
    "# Implementing 10-fold here\n",
    "for train_index, test_index in cv.split(X,y):\n",
    "    # split data to 9 folds training and 1 fold testing\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # implementing preprocessing scheme on only training data\n",
    "    # fitting testing data to preprocessing method\n",
    "    normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = normalizer.transform(X_train)\n",
    "    X_test = normalizer.transform(X_test)\n",
    "    \n",
    "    # SVM classifier algorithm selected\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # compute different metrics, print for each fold, store for analysis\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('Training accuracy is: {}, testing accuracy is: {}'.format(train_acc,acc))\n",
    "    \n",
    "    precs = precision_score(y_test, y_pred, average='macro')\n",
    "    recs = recall_score(y_test, y_pred, average='macro')\n",
    "    f1s = f1_score(y_test, y_pred, average='macro')\n",
    "    hloss = hamming_loss(y_test, y_pred)\n",
    "    print('Precision score: {}'.format(precs))\n",
    "    print('Recall score: {}'.format(recs))\n",
    "    print('F1 score: {}'.format(f1s))\n",
    "    print('Hamming loss: {}'.format(hloss))\n",
    "    \n",
    "    store_train_acc.append(train_acc)\n",
    "    store_acc.append(acc)\n",
    "    \n",
    "    store_precs.append(precs)\n",
    "    store_recs.append(recs)\n",
    "    store_f1s.append(f1s)\n",
    "    store_hloss.append(hloss)\n",
    "\n",
    "# Compute and print average and standard deviation of metrics\n",
    "print('Average training accuracy: {}, standard deviation: {}'.format(np.mean(np.array(store_train_acc)),np.std(np.array(store_train_acc))))\n",
    "print('Average testing accuracy: {}, standard deviation: {}'.format(np.mean(np.array(store_acc)),np.std(np.array(store_acc))))\n",
    "print('Average precision score: {}, standard deviation: {}'.format(np.mean(np.array(store_precs)),np.std(np.array(store_precs))))\n",
    "print('Average recall score: {}, standard deviation: {}'.format(np.mean(np.array(store_recs)),np.std(np.array(store_recs))))\n",
    "print('Average f1 score: {}, standard deviation: {}'.format(np.mean(np.array(store_f1s)),np.std(np.array(store_f1s))))\n",
    "print('Average hamming loss score: {}, standard deviation: {}'.format(np.mean(np.array(store_hloss)),np.std(np.array(store_hloss))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 1.0, testing accuracy is: 0.9388888888888889\n",
      "Precision score: 0.948391812865497\n",
      "Recall score: 0.9364181286549709\n",
      "F1 score: 0.9361604808973232\n",
      "Hamming loss: 0.06111111111111111\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9944444444444445\n",
      "Precision score: 0.9941176470588236\n",
      "Recall score: 0.99375\n",
      "F1 score: 0.9937438905180841\n",
      "Hamming loss: 0.005555555555555556\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9833333333333333\n",
      "Precision score: 0.9854761904761904\n",
      "Recall score: 0.983625730994152\n",
      "F1 score: 0.9840189090189089\n",
      "Hamming loss: 0.016666666666666666\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9833333333333333\n",
      "Precision score: 0.9830065359477125\n",
      "Recall score: 0.9832989336085312\n",
      "F1 score: 0.9828435157846924\n",
      "Hamming loss: 0.016666666666666666\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9888888888888889\n",
      "Precision score: 0.9897368421052631\n",
      "Recall score: 0.9888888888888889\n",
      "F1 score: 0.989018909018909\n",
      "Hamming loss: 0.011111111111111112\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9833333333333333\n",
      "Precision score: 0.9849282296650719\n",
      "Recall score: 0.9838888888888888\n",
      "F1 score: 0.9839906249208574\n",
      "Hamming loss: 0.016666666666666666\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9722222222222222\n",
      "Precision score: 0.972579426507445\n",
      "Recall score: 0.9717261904761905\n",
      "F1 score: 0.9712086005073809\n",
      "Hamming loss: 0.027777777777777776\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9441340782122905\n",
      "Precision score: 0.9574149047833258\n",
      "Recall score: 0.9433608531131752\n",
      "F1 score: 0.9457602888037672\n",
      "Hamming loss: 0.055865921787709494\n",
      "Training accuracy is: 0.9993819530284301, testing accuracy is: 0.9385474860335196\n",
      "Precision score: 0.9420175438596491\n",
      "Recall score: 0.9378018575851392\n",
      "F1 score: 0.9368917442601653\n",
      "Hamming loss: 0.061452513966480445\n",
      "Training accuracy is: 1.0, testing accuracy is: 0.9608938547486033\n",
      "Precision score: 0.9667464114832536\n",
      "Recall score: 0.9614035087719298\n",
      "F1 score: 0.9605388759800524\n",
      "Hamming loss: 0.03910614525139665\n",
      "Average training accuracy: 0.9999381953028431, standard deviation: 0.000185414091470959\n",
      "Average testing accuracy: 0.9688019863438857, standard deviation: 0.020463064008200773\n",
      "Average precision score: 0.9724415544752232, standard deviation: 0.01722986345615534\n",
      "Average recall score: 0.9684162980981867, standard deviation: 0.02098137488581166\n",
      "Average f1 score: 0.9684175839710141, standard deviation: 0.020922430448691576\n",
      "Average hamming loss score: 0.031198013656114215, standard deviation: 0.02046306400820077\n"
     ]
    }
   ],
   "source": [
    "# if results are not enough, or we just want a more robust model,\n",
    "# perform hyperparameter tuning. I will use exhaustive gridsearch\n",
    "\n",
    "# Implementing 10-fold cross validation to test model\n",
    "cv = KFold(n_splits=10, shuffle=False, random_state=234)\n",
    "inner_cv = KFold(n_splits=10, shuffle=False, random_state=234)\n",
    "\n",
    "# lists to store model metrics for analysis\n",
    "store_train_acc = []\n",
    "store_acc = []\n",
    "\n",
    "store_precs = []\n",
    "store_recs = []\n",
    "store_f1s = []\n",
    "store_hloss = []\n",
    "\n",
    "# Implementing 10-fold here\n",
    "for train_index, test_index in cv.split(X,y):\n",
    "    # split data to 9 folds training and 1 fold testing\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # implementing preprocessing scheme on only training data\n",
    "    # fitting testing data to preprocessing method\n",
    "    normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = normalizer.transform(X_train)\n",
    "    X_test = normalizer.transform(X_test)\n",
    "    \n",
    "    params = {'C': np.linspace(1,1000,10,dtype=int), 'kernel':['rbf','linear','sigmoid'],\n",
    "             'gamma': np.linspace(0.001,0.1,10)}\n",
    "    \n",
    "    # SVM classifier algorithm selected\n",
    "    clf = GridSearchCV(estimator=SVC(), param_grid=params, cv=inner_cv, scoring='accuracy', n_jobs=4)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # compute different metrics, print for each fold, store for analysis\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('Training accuracy is: {}, testing accuracy is: {}'.format(train_acc,acc))\n",
    "    \n",
    "    precs = precision_score(y_test, y_pred, average='macro')\n",
    "    recs = recall_score(y_test, y_pred, average='macro')\n",
    "    f1s = f1_score(y_test, y_pred, average='macro')\n",
    "    hloss = hamming_loss(y_test, y_pred)\n",
    "    print('Precision score: {}'.format(precs))\n",
    "    print('Recall score: {}'.format(recs))\n",
    "    print('F1 score: {}'.format(f1s))\n",
    "    print('Hamming loss: {}'.format(hloss))\n",
    "    \n",
    "    store_train_acc.append(train_acc)\n",
    "    store_acc.append(acc)\n",
    "    \n",
    "    store_precs.append(precs)\n",
    "    store_recs.append(recs)\n",
    "    store_f1s.append(f1s)\n",
    "    store_hloss.append(hloss)\n",
    "\n",
    "# Compute and print average and standard deviation of metrics\n",
    "print('Average training accuracy: {}, standard deviation: {}'.format(np.mean(np.array(store_train_acc)),np.std(np.array(store_train_acc))))\n",
    "print('Average testing accuracy: {}, standard deviation: {}'.format(np.mean(np.array(store_acc)),np.std(np.array(store_acc))))\n",
    "print('Average precision score: {}, standard deviation: {}'.format(np.mean(np.array(store_precs)),np.std(np.array(store_precs))))\n",
    "print('Average recall score: {}, standard deviation: {}'.format(np.mean(np.array(store_recs)),np.std(np.array(store_recs))))\n",
    "print('Average f1 score: {}, standard deviation: {}'.format(np.mean(np.array(store_f1s)),np.std(np.array(store_f1s))))\n",
    "print('Average hamming loss score: {}, standard deviation: {}'.format(np.mean(np.array(store_hloss)),np.std(np.array(store_hloss))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 112, 'gamma': 0.012, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final training and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Complete\n",
      "Final models saved\n"
     ]
    }
   ],
   "source": [
    "# we completed the hyperparameter tuning and found the\n",
    "# best parameters above\n",
    "# There was only a slight improvement in accuracy but \n",
    "# these efforts are necessary. Caveat: the dataset was very\n",
    "# simple to train so only modest improvements were seen. If\n",
    "# computational resources allow, I would run gridsearch through\n",
    "# an even wider set of parameters (all on local now)\n",
    "\n",
    "normalizer = preprocessing.StandardScaler().fit(X)\n",
    "X_train = normalizer.transform(X)\n",
    "y_train = y\n",
    "    \n",
    "clf = SVC(C=112, gamma=0.012, kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "print('Final Training Complete')\n",
    "\n",
    "filename = 'normalizer.pkl'\n",
    "pickle.dump(normalizer, open(filename,'wb'))\n",
    "filename = 'svclassifier.pkl'\n",
    "pickle.dump(clf, open(filename,'wb'))\n",
    "print('Final models saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
